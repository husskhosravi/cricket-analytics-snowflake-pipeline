### ğŸ“Œ Cricket Analytics Project Summary (Scalable Data Warehouse on Snowflake)

This project showcases a fully automated, production-grade data pipeline built on Snowflake for cricket analytics. It ingests semi-structured match data in JSON format from AWS S3 using Snowpipe, processes it through Streams and Tasks, and transforms it into a clean, analytical star schema. The model includes fact and dimension tables capturing players, teams, matches, and ball-by-ball events. Key features include incremental loading, dynamic JSON flattening, surrogate key generation, SCD handling, and dependency-managed task orchestration, making it a scalable solution for real-time sports data warehousing and analysis.

---

### ğŸ“¦ Project Overview

* End-to-end pipeline using Snowflake & AWS S3
* Handles nested JSON for cricket match data
* Fully automated with Snowpipe, Streams, and Tasks
* Final model supports analytical queries and reporting

---

### ğŸ§± Architecture

| Component      | Technology                 |
| -------------- | -------------------------- |
| Cloud Storage  | AWS S3                     |
| Data Warehouse | Snowflake                  |
| File Format    | JSON                       |
| Ingestion      | Snowpipe (auto-ingest)     |
| Processing     | Snowflake Tasks + Streams  |
| Scheduling     | 1-minute DAG orchestration |

ğŸ“Œ **Visual pipeline:**

![Cricket Analytics Snowflake Project](https://github.com/user-attachments/assets/c65fde7c-ff81-4a2c-90d6-daf15b9c9d8d)


---

### ğŸ§  Core Concepts Demonstrated

* Semi-structured data handling (JSON)
* Auto-ingestion from S3 using Snowpipe
* Incremental loads with Streams
* Orchestration with dependency-based Tasks
* SCD Type-0 and Type-1 modelling
* Complex SQL with arrays, object parsing, and flattening

---

### ğŸ§© Data Model Design

**Tables:**

* `DW.MATCH_INFO` â€“ Match-level metadata
* `DW.MATCH_INNINGS` â€“ Ball-by-ball fact table
* `DW.PLAYERS` â€“ Players with multi-team support (array)
* `DW.TEAMS` â€“ Teams with type (club/national)

**Highlights:**

* Surrogate keys via Snowflake sequences
* `FILENAME` as deduplication + join key
* `IS_POWERPLAY` derived using `CASE`, fallback defaults

---

### ğŸ”„ Pipeline Flow

```
1. Upload JSON to S3
2. Snowpipe loads to RAW.RAW_DATA
3. Stream detects new rows
4. Tasks process and flatten JSON:
    - Teams
    - Players
    - Match Info
    - Innings
5. DW Layer loads using sequenced keys
```

![task_flow](https://github.com/user-attachments/assets/034804c5-09cb-4bb0-967e-f15f89e82af3)

---

### ğŸ“ Repo File Layout

```
ğŸ“‚ cricket-snowflake-dw
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ task_flow.png
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ raw_layer.sql
â”‚   â”œâ”€â”€ staging_layer.sql
â”‚   â”œâ”€â”€ dw_layer.sql
â”‚   â””â”€â”€ ddl_all_tables.sql
â””â”€â”€ queries/
    â””â”€â”€ match_analysis_queries.sql
```

---

### ğŸ§  Project Capabilities Demonstrated

* Scalable ingestion of raw match data from AWS S3 using Snowpipe
* Event-driven pipeline with native orchestration via Snowflake Tasks
* Normalisation and flattening of complex, nested JSON structures
* Star schema modelling optimised for analytical performance
* Automated surrogate key generation and controlled dimensional joins
*  Managing SCD logic using `MERGE`, `ARRAY_CAT`, `ARRAY_DISTINCT`
* Scheduling DAGs using Snowflake native features (no Airflow needed)

---

### âœï¸ Final Notes
This project was built to practice near-production ETL orchestration on Snowflake using real semi-structured sports data. All logic, dependencies, and schema design were implemented natively without third-party orchestration or transformation tools.

âœ… Easily extendable with dashboards or materialised views

âœ… Plug-and-play with public cricket data from [CricSheet](https://cricsheet.org/)
